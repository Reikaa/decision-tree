{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A small sample data set with four features: two numerical and two categorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data='MPG, cylinders, HP, weight\\ngood, 4, 75, light\\nbad, 6, 90, medium\\nbad, 4, 110, medium\\nbad, 8, 175, weighty\\nbad, 6, 95, medium\\nbad, 4, 94, light\\nbad, 4, 95, light\\nbad, 8, 139, weighty\\nbad, 8, 190, weighty\\nbad, 8, 145, weighty\\nbad, 6, 100, medium\\ngood, 4, 92, medium\\nbad, 6, 100, weighty\\nbad, 8, 170, weighty\\ngood, 4, 89, medium\\ngood, 4, 65, light\\nbad, 6, 85, medium\\ngood, 4, 81, light\\nbad, 6, 95, medium\\ngood, 4, 93, light'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converts a raw data string into clean X and Y matrixes\n",
    "def process(data_string, numeric, target):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    numeric: a list of columns names to be coerced to numeric values\n",
    "    target: column name that represents target labels\n",
    "    \"\"\"\n",
    "    # remove whitespace\n",
    "    data=\",\".join(data_string.split(\", \"))\n",
    "    # build dataframe header row\n",
    "    cols = data.splitlines()[0].split(',')\n",
    "    # build data frame from a list of strings\n",
    "    data = data.splitlines()[1:]\n",
    "    df = pd.DataFrame.from_dict(\n",
    "    map(\n",
    "        lambda line: dict(zip(cols, line.split(','))),\n",
    "        data\n",
    "    ))\n",
    "    # coerce numeric columns into numeric data types\n",
    "    for col in numeric:\n",
    "        df.loc[:, col] = pd.to_numeric(df.loc[:, col], errors='coerce')\n",
    "    \n",
    "    # finally, return the X data matrix (dataframe), and the Y data labels (series)\n",
    "    return df.drop([target], axis=1), pd.Series(df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train = process(data, numeric=['HP'], target='MPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a class representing a single decision tree, with methods to fit training data, visualize the resultant tree, and predict binary classes on new test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # instantiate the model\n",
    "        self.nodes = []\n",
    "    \n",
    "    # x_train should be a Pandas DataFrame\n",
    "    # y_train should be a Pandas Series\n",
    "    def fit(self, x_train, y_train, feature_types, max_depth=4):\n",
    "        \n",
    "        self.features = x_train.columns.tolist()\n",
    "        self.target = y_train.name\n",
    "        self.target_values = y_train.unique().tolist()\n",
    "        self.feature_types = feature_types\n",
    "        \n",
    "        # take in training data and append columns for categorized flag\n",
    "        # and level labels (n=max_depth)\n",
    "        self.df = pd.concat([x_train, pd.DataFrame(y_train)], axis=1)\n",
    "        self.df.loc[:, 'is_categorized'] = 0\n",
    "        for i in range(max_depth):\n",
    "            self.df.loc[:, 'level_' + str(i+1)] = None\n",
    "\n",
    "        # create the top-level node\n",
    "        self.nodes.append(Node(\"Y\", x_train.index.tolist(), self))\n",
    "        \n",
    "        # traverse the tree, building sub-nodes on the fly\n",
    "        for level in range(1, max_depth + 1):\n",
    "            \n",
    "            # stopping criteria 1 (max depth reached)\n",
    "            if level == max_depth:\n",
    "                print \"Fitting stopped: max depth reached.\"\n",
    "                break\n",
    "            \n",
    "            # building the tree recursively\n",
    "            # get all existing nodes at level i\n",
    "            for node in (node for node in self.nodes if len(node.name) == level):\n",
    "                if node.is_pure == 0:\n",
    "                    # create new nodes and add to the tree's node list\n",
    "                    self.nodes.extend(node.split())\n",
    "                else:\n",
    "                    pass # pure node  \n",
    "\n",
    "            # stopping criteria 2 (fully categorized)\n",
    "            if sum(self.df.is_categorized) == len(self.df):\n",
    "                print \"Fitting stopped: data fully categorized.\"\n",
    "                break\n",
    "         \n",
    "        self.visualize()\n",
    "    \n",
    "    \n",
    "    def visualize(self):\n",
    "        \n",
    "        # establish a mapping of tree node objects and their names\n",
    "        node_map = dict(zip(map(lambda node: node.name, f.nodes),\n",
    "                 self.nodes))\n",
    "        \n",
    "        depth = max(map(lambda node: len(node.name), self.nodes))\n",
    "        width = 100\n",
    "\n",
    "        # iterate through each level (zero based)\n",
    "        for level in range(depth):\n",
    "            name_string = ''\n",
    "            rule_class_string = ''\n",
    "            gain_string = ''\n",
    "            elements = 2**level\n",
    "            r = range(elements)\n",
    "            # iterate through each element position within level (zero based)\n",
    "            for position in range(elements):\n",
    "                expected_name=''\n",
    "                # iterate through each letter in node name\n",
    "                for letter in range(level+1):\n",
    "                    \n",
    "                    # this process uses the index of the position in tree to\n",
    "                    # determine the name of the node\n",
    "                    size = elements / (2**letter)\n",
    "                    lists = [r[i:i + size] for i in range(0, len(r), size)]\n",
    "                    sliced_lists = lists[::2]\n",
    "                    l = []\n",
    "                    map(l.extend, sliced_lists)\n",
    "                    \n",
    "                    if position in l:\n",
    "                        expected_name += 'Y'\n",
    "                    else:\n",
    "                        expected_name += 'N'\n",
    "                \n",
    "                # if the \"expected node\" exists, display some details on it\n",
    "                if expected_name in node_map:\n",
    "                    if node_map[expected_name].is_pure:\n",
    "                        # add name to name line\n",
    "                        name_string += (width / (elements + 1)) * ' '\n",
    "                        name_string += node_map[expected_name].name\n",
    "                        \n",
    "                        # add class to detail line\n",
    "                        rule_class_string += ((width / (elements + 1)) * ' ')[:-4]\n",
    "                        rule_class_string += ('class: ' + node_map[expected_name].label)\n",
    "                        \n",
    "                        # add gain to gain line\n",
    "                        gain_string += (width / (elements + 1)) * ' '\n",
    "                        gain_string += '----'\n",
    "\n",
    "                    else:\n",
    "                        # add name to name line\n",
    "                        name_string += (width / (elements + 1)) * ' '\n",
    "                        name_string += node_map[expected_name].name\n",
    "                        \n",
    "                        # add rule to detail line\n",
    "                        rule_class_string += ((width / (elements + 1)) * ' ')[:-4]\n",
    "                        rule_class_string += (node_map[expected_name].rule['feature'] + \\\n",
    "                                              ': ' + str(node_map[expected_name].rule['value']))\n",
    "                        \n",
    "                        # add gain to gain line\n",
    "                        gain_string += ((width / (elements + 1)) * ' ')[:-4]\n",
    "                        gain_string += ('gain: ' + str(node_map[expected_name].rule['gain']))\n",
    "                        \n",
    "                else: # node doesnt exist, print blanks\n",
    "                    name_string += (((width / (elements + 1)) * ' ') + '   ')\n",
    "                    rule_class_string += (((width / (elements + 1)) * ' ') + '          ')\n",
    "                    gain_string += (((width / (elements + 1)) * ' ') + '        ')\n",
    "                    \n",
    "            print name_string\n",
    "            print rule_class_string\n",
    "            print gain_string + '\\n\\n'\n",
    "            # print space newlines with slashes\n",
    "        \n",
    "    \n",
    "    # x_test should be a Pandas DataFrame\n",
    "    def predict(self, x_test):\n",
    "        \n",
    "        # establish a mapping of tree node objects and their names\n",
    "        node_map = dict(zip(map(lambda node: node.name, f.nodes),\n",
    "                 self.nodes))\n",
    "        \n",
    "        # make a prediction for each observation vector\n",
    "        predictions = []\n",
    "        for i, row in x_test.iterrows():\n",
    "            # always start at top level node\n",
    "            n = 'Y'\n",
    "            while True:\n",
    "                # check if node at index is pure; if so, declare a label\n",
    "                if node_map[n].is_pure:\n",
    "                    predictions.append(node_map[n].label)\n",
    "                    break # from while\n",
    "                 \n",
    "                f_type = node_map[n].rule['f_type']\n",
    "                feature = node_map[n].rule['feature']\n",
    "                value = node_map[n].rule['value']\n",
    "                \n",
    "                if f_type == 'discrete':\n",
    "                    if row[feature] == value:\n",
    "                        n += 'Y'\n",
    "                    else:\n",
    "                        n += 'N'\n",
    "                else: # continuous\n",
    "                    if row[feature] > value:\n",
    "                        n += 'Y'\n",
    "                    else:\n",
    "                        n += 'N'\n",
    "        \n",
    "        # finally, add a new predicted label column to the test data, and return \n",
    "        x_test[self.target] = pd.Series(predictions)\n",
    "        return x_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within the tree, Node objects represent decision points. Nodes assess all available decision criteria, and selects the most powerful split based on an information gain calculation (change in entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, name, indices, parent_tree):\n",
    "        \n",
    "        self.name = name\n",
    "        self.indices = indices\n",
    "        self.parent_tree = parent_tree\n",
    "        self.is_pure = False\n",
    "        self.label = None\n",
    "        self.rule = {}\n",
    "        \n",
    "        self.check_purity()\n",
    "        # add node labels to parent tree df\n",
    "        self.parent_tree.df.loc[self.indices, 'level_' + str(len(self.name))] = self.name\n",
    "    \n",
    "    \n",
    "    def check_purity(self):\n",
    "        \n",
    "        uniques = self.parent_tree.df.loc[self.indices, self.parent_tree.target].unique()\n",
    "        if len(uniques) == 1:\n",
    "            self.is_pure = True\n",
    "            # set all data at node to \"is_categorized\" = 1\n",
    "            self.parent_tree.df.loc[self.indices, 'is_categorized'] = 1\n",
    "            self.label = uniques[0]\n",
    "        \n",
    "    \n",
    "    def info_gain(self, yes_pos, yes_neg, no_pos, no_neg):\n",
    "    \n",
    "        def logs(x, y):\n",
    "            x = float(x)\n",
    "            y = float(y)\n",
    "            if x==0 and y==0:\n",
    "                return 0\n",
    "            elif x==0:\n",
    "                return (y * math.log((y+x)/y, 2))\n",
    "            elif y==0:\n",
    "                return (x * math.log((x+y)/x, 2))\n",
    "            else:\n",
    "                return (x * math.log((x+y)/x, 2)) + (y * math.log((y+x)/y, 2))\n",
    "\n",
    "        return (logs(yes_pos + no_pos, yes_neg + no_neg) - logs(yes_pos, yes_neg) - \\\n",
    "                logs(no_pos, no_neg)) / sum([yes_pos, yes_neg, no_pos, no_neg])\n",
    "    \n",
    "    \n",
    "    def get_split_candidates(self, df):\n",
    "        \n",
    "        split_candidates = {'discrete':[], 'continuous':[]}\n",
    "        \n",
    "        # get lists of all possible split candidates\n",
    "        for feature, f_type in zip(self.parent_tree.features, self.parent_tree.feature_types):\n",
    "            # for discrete features, the candidates are every unique value\n",
    "            if f_type == 'discrete':\n",
    "                split_candidates['discrete'].extend(\n",
    "                    [(feature, value) for value in df[feature].unique().tolist()])\n",
    "            # for continuous features, we sort values and take midpoints between\n",
    "            # consecutive observations having different labels\n",
    "            else:\n",
    "                df_sorted = df.sort_values(feature).reset_index()\n",
    "                for i in range(len(df_sorted) - 1):\n",
    "                    df_pair = df_sorted.loc[i:i+1, :].reset_index()\n",
    "                    if df_pair.loc[0, self.parent_tree.target] != \\\n",
    "                    df_pair.loc[1, self.parent_tree.target]:\n",
    "                          split_candidates['continuous'].append(\n",
    "                              (feature, df_pair[feature].mean()))\n",
    "                \n",
    "        return split_candidates\n",
    "    \n",
    "    def choose_split(self, df, split_candidates):\n",
    "        \n",
    "        # search split candidates for highest information gain\n",
    "        highest_gain = 0\n",
    "        chosen_split = {}\n",
    "        \n",
    "        # TODO: does it matter if we use \"good\" or \"bad\" as the classifer + and - ??\n",
    "        for feature, value in split_candidates['discrete']:\n",
    "            gain = self.info_gain(\n",
    "                # split decision: YES, observation label YES\n",
    "                sum((df[feature]==value) & (df[self.parent_tree.target]== \\\n",
    "                                            self.parent_tree.target_values[0])),\n",
    "                # split decision: YES, observation label NO\n",
    "                sum((df[feature]==value) & (df[self.parent_tree.target]!= \\\n",
    "                                            self.parent_tree.target_values[0])),\n",
    "                # split decision: NO, observation label YES\n",
    "                sum((df[feature]!=value) & (df[self.parent_tree.target]== \\\n",
    "                                            self.parent_tree.target_values[0])),\n",
    "                # split decision: NO, observation label NO\n",
    "                sum((df[feature]!=value) & (df[self.parent_tree.target]!= \\\n",
    "                                            self.parent_tree.target_values[0]))\n",
    "            )\n",
    "            ### TEST ###\n",
    "            print self.name\n",
    "            print feature, value, gain\n",
    "            ############\n",
    "            if gain > highest_gain:\n",
    "                highest_gain = round(gain, 3)\n",
    "                chosen_split = {'f_type':'discrete',\n",
    "                                'feature': feature,\n",
    "                                'value': value,\n",
    "                                'gain': highest_gain}\n",
    "        \n",
    "        for feature, value in split_candidates['continuous']:\n",
    "            gain = self.info_gain(\n",
    "                # split decision: YES, observation label YES\n",
    "                sum((df[feature]>value) & (df[self.parent_tree.target]== \\\n",
    "                                           self.parent_tree.target_values[0])),\n",
    "                # split decision: YES, observation label NO\n",
    "                sum((df[feature]>value) & (df[self.parent_tree.target]!= \\\n",
    "                                           self.parent_tree.target_values[0])),\n",
    "                # split decision: NO, observation label YES\n",
    "                sum((df[feature]<=value) & (df[self.parent_tree.target]== \\\n",
    "                                            self.parent_tree.target_values[0])),\n",
    "                # split decision: NO, observation label NO\n",
    "                sum((df[feature]<=value) & (df[self.parent_tree.target]!= \\\n",
    "                                            self.parent_tree.target_values[0]))\n",
    "            )\n",
    "            ### TEST ###\n",
    "            print self.name\n",
    "            print feature, value, gain\n",
    "            ############\n",
    "            if gain > highest_gain:\n",
    "                highest_gain = round(gain, 3)\n",
    "                chosen_split = {'f_type': 'continuous',\n",
    "                                'feature': feature,\n",
    "                                'value': value,\n",
    "                                'gain': highest_gain}\n",
    "    \n",
    "            return chosen_split\n",
    "    \n",
    "    def split(self):\n",
    "        \n",
    "        # create a copy of the node's domain in training data\n",
    "        df = copy.deepcopy(\n",
    "            self.parent_tree.df.loc[\n",
    "                self.indices,\n",
    "                self.parent_tree.features + [self.parent_tree.target]])\n",
    "        \n",
    "        # list all possible split points\n",
    "        split_candidates = self.get_split_candidates(df)\n",
    "        \n",
    "        # search the list for highest information gain\n",
    "        chosen_split = self.choose_split(df, split_candidates)\n",
    "        self.rule = chosen_split\n",
    "        \n",
    "        # perform the split by splitting the current node's domain on the new rule\n",
    "        if chosen_split['f_type'] == 'continuous':\n",
    "            \n",
    "            yes_index = df[df[chosen_split['feature']] > chosen_split['value']].index.tolist()\n",
    "            no_index = df[df[chosen_split['feature']] <= chosen_split['value']].index.tolist()\n",
    "            \n",
    "            return [Node(self.name + 'Y', yes_index, self.parent_tree),\n",
    "                   Node(self.name + 'N', no_index, self.parent_tree)]\n",
    "\n",
    "        else: # discrete\n",
    "            \n",
    "            yes_index = df[df[chosen_split['feature']] == chosen_split['value']].index.tolist()\n",
    "            no_index = df[df[chosen_split['feature']] != chosen_split['value']].index.tolist()\n",
    "            \n",
    "            return [Node(self.name + 'Y', yes_index, self.parent_tree),\n",
    "                   Node(self.name + 'N', no_index, self.parent_tree)]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      "cylinders 4 0.468057773906\n",
      "Y\n",
      "cylinders 6 0.191631204007\n",
      "Y\n",
      "cylinders 8 0.15307795339\n",
      "Y\n",
      "weight light 0.191631204007\n",
      "Y\n",
      "weight medium 0.00580214901435\n",
      "Y\n",
      "weight weighty 0.191631204007\n",
      "Y\n",
      "HP 83.0 0.309840304716\n",
      "YY\n",
      "cylinders 4 0.0\n",
      "YY\n",
      "weight light 4.93432455389e-17\n",
      "YY\n",
      "weight medium 9.86864910778e-17\n",
      "YY\n",
      "HP 93.5 0.918295834054\n",
      "Fitting stopped: data fully categorized.\n",
      "                                                  Y\n",
      "                                              cylinders: 4\n",
      "                                              gain: 0.468\n",
      "\n",
      "\n",
      "                                 YY                                 YN\n",
      "                             HP: 93.5                             class: bad\n",
      "                             gain: 0.918                                 ----\n",
      "\n",
      "\n",
      "                    YYY                    YYN                                              \n",
      "                class: bad                class: good                                                            \n",
      "                    ----                    ----                                                        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting a new tree with training data; visualizing the tree\n",
    "f = Tree()\n",
    "f.fit(x_train, y_train, feature_types=['continuous', 'discrete', 'discrete'], max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try predicting new binary categories with some test data\n",
    "data_test=\"MPG, cylinders, HP, weight\\n?,4,93,weighty\\n?,8,70,light\\n?,6,113,medium\\n?,6,95,weighty\\n?,4,115,medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = process(data_test, numeric=['HP'], target='MPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HP</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>weight</th>\n",
       "      <th>MPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>weighty</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>light</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>6</td>\n",
       "      <td>medium</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "      <td>weighty</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>medium</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HP cylinders   weight   MPG\n",
       "0   93         4  weighty  good\n",
       "1   70         8    light   bad\n",
       "2  113         6   medium   bad\n",
       "3   95         6  weighty   bad\n",
       "4  115         4   medium   bad"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
